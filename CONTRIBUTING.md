# Contributing to ossf-cve-benchmark

We welcome contributions to the ossf-cve-benchmark project. If you want
to contribute benchmark data, analysis tool drivers, or report generators,
please go ahead and open a pull request!

Contributions to this project are
[released](https://help.github.com/articles/github-terms-of-service/#6-contributions-under-repository-license)
to the public under the [project's open source license](LICENSE).


## Contributing benchmark data 

The benchmark CVEs are located in the [CVEs](CVEs) directory. The
benchmark CVEs are maintained by the community and additions and
changes are welcome as pull requests.

For a CVE to be used as a benchmark you must provide details of:

- One vulnerable and one patched commit
- At least one weakness for the vulnerable commit

For more information, see [Benchmark CVEs](docs/benchmark-CVEs.md).

## Contributing code

This project contains two source code directories: 

- [src](src): contains the core tooling, and is
primarily maintained by a core team of developers
- [contrib](contrib): contains utility scripts, such as the [analysis tool
drivers](contrib/tools) and [report generators](contrib/reports).

### Contributing analysis tool drivers

Analysis tool drivers are small scripts that run an actual analysis
tool when invoked by `bin/cli run ...`.

To add support for a new driver, add a new directory to
the [contrib/tools](contrib/tools), and read the requirements for the
drivers in the [docs](docs/analysis-tools.md).

### Contributing report generators

Report generators process the CVE data and analysis tool results into
different kinds of reports when invoked through `bin/cli report ...`.

To add support for a new report generator, add a new directory to the
[contrib/reports](contrib/reports) with the implementation. Adjust
the implementation of [src/cli.ts](src/cli.ts) to support the new
report generator.

### Code quality

This project uses GitHub Actions for CI, see
[.github/workflows](.github/workflows). For a slightly faster
turnaround time, it is recommended that `npm run-script all-checks` is
run locally before pushing.

#### Checks

The following analysis tools are run as CI, new alerts from these must be considered: 

- [`codeql`](.github/workflows/codeql-analysis.yml): `+security-and-quality` for JavaScript/TypeScript
  - (CI only)
- [`OSSAR`](.github/workflows/ossar-analysis.yml): default configuration
  - (CI only)
- [`prettier`](.github/workflows/Checks.yml): see [.prettierrc.json](.prettierrc.json), [.prettierignore](.prettierignore). 
  - Can also be run locally as `npm run-script lint` or `npx prettier -c .`
  - Run `npx prettier -w .` locally to fix problems
- [`typescript-eslint`](.github/workflows/Checks.yml): see [.eslintrc.js](.eslintrc.js), [.eslintignore](.eslintignore). 
  - Can also be run locally as `npm run-script lint` or `npx eslint .`

#### Tests

This project uses [`jest`](.github/workflows/Checks.yml) for testing,
failures from these tests must be addressed. Use `npm run-script test`
or `npx jest` to run the tests locally.
