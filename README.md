# ossf-cve-benchmark

Note, this project is still in deveplopment.  The README files and may
not be up entirely to date, and some features may be missing.

TODO intro


```
$ CVES="CVE-2018-16492 CVE-2020-4066"

$ bin/cli download $CVES

$ contrib/tools/eslint/bin/install.sh work/eslint-default

...

$ bin/cli run --tool-id eslint-default --config config.json $CVES

$ bin/cli export --tool-id eslint-default $CVES

$ bin/cli report 

$ cat work/reports/overview-table.txt
╔════════════════╤═════════════════╤═════════════════════════════════════════════╤════════════╤════════════╗
║ CVE            │ CWEs            │ Repository                                  │ Weaknesses │ Downloaded ║
╟────────────────┼─────────────────┼─────────────────────────────────────────────┼────────────┼────────────╢
║ CVE-2018-16492 │ CWE-400 CWE-471 │ https://github.com/justmoon/node-extend.git │ 1          │ ALL        ║
║ CVE-2020-4066  │ CWE-078 CWE-088 │ https://github.com/erelsgl/limdu.git        │ 1          │ ALL        ║
╚════════════════╧═════════════════╧═════════════════════════════════════════════╧════════════╧════════════╝

$ cat work/reports/Negative-delta-alert-counts-rules-table.txt
╔════════════════╤═════════════════════════════════════════════════════╤══════════════════════════════════════════╗
║ CVE            │ Descriptions                                        │ eslint-default                           ║
╟────────────────┼─────────────────────────────────────────────────────┼──────────────────────────────────────────╢
║ CVE-2018-16492 │ Prototype pollution in utility function             │ security/detect-object-injection: -3 (2) ║
║ CVE-2020-4066  │ Unsafe shell command constructed from library input │ security/detect-child-process: -1 (3)    ║
╚════════════════╧═════════════════════════════════════════════════════╧══════════════════════════════════════════╝
```
## Legal caveats

This project enables the bulk-running of analysis tools on commits
related to CVEs, and subsequent report generation.

Be aware that your license for some analysis tools may restrict how
you may use them. These restrictions may be on how the analysis tool
is run, what it is run on, and how the results are published.

## Usage

`bin/cli` is the CLI  entry point for this project:
```
$ bin/cli -h
usage: bin/cli [-h] {export,download,run,report} ...

CLI for ossf-cve-benchmark

- download: Downloads the relevant commits for the selected CVEs
- run: Runs an analysis tool on the source code of the selected CVEs
- export: Exports CVE and analysis tool data for the selected CVEs into a single file
- report: Generates reports based on the content of an exported file
- tools: Displays the analysis tools that are available for the `run` command

...

```

See the above example session for how each command can be used, or use
the builtin help for each command (for example: `bin/cli download
-h`).

Each command uses a configuration file that is either specified by
`--config my/path/config.json`, or implicitly assumed present at
`config.json` of the `bin/cli`'s working directory. Some commands may not
work if neither of these are present. The options that are set in
`config.json` may be overriden individually on a per-command
basis with command-line arguments. As an example, the directory CVE
commits are downloaded to can be changed with the `--sources`
argument: `bin/cli download --sources-dir my/other/sources/dir -` .


### Getting started

The initial install steps for this project are:

```
$ cd ossf-cve-benchmark
$ npm i
$ tsc
```

Before you can use `bin/cli run` on an analysis tool, you need to
install the analysis tool and then configure the plugin for the analysis tool.

Each analysis tool plugin describes how it should be set up, see
[eslint/README.md](contrib/tools/eslint/README.md) as an example, or
just try to run [eslint/bin/install.sh](contrib/tools/eslint/bin.sh).

### Selecting CVEs of interest

Most commands support selecting the CVEs that should be processed.

There are several ways to specify CVEs. The two basic ways are:

- An explicit list of CVE identifiers: e.g. `bin/cli download CVE-2017-18352 CVE-2018-3743`
- A wildcard operator that selects all available BCVEs: `bin/cli download '*'`

In addition, to this, there is a tiny query language, that can select CVEs based on year, CWE, and more. For example:

- The CVEs from 2020 `bin/cli download year:2020`
- The CVEs with CWE-88 or CWE-89 `bin/cli download CWE-88 CWE-89`

Finally, all of the above can be provided as a line-separated input stream in stdin.
For example:

```
$ echo CVE-2017-18352 >> my-cves.txt
$ echo CVE-2018-3743 >> my-cves.txt
$ cat my-cves.txt | bin/cli export -
```

Note that CVEs that are considered to be "incomplete" will not be
selected by default, see [CVEs](CVEs/README.md) for details.

## Contributing Data 

** COMMUNITY COMMUNITY COMMUNITY **


### Register or edit a CVE benchmark

The benchmark CVEs are located in the [CVEs](CVEs) directory. The
CVE benchmarks are maintained by the community and additions and
changes are welcome as pull requests.

The essence of the rules for a CVE benchmark can be seen below, the
full details can be seen in the [docs](CVEs/README.md):

- There is a vulnerable and a patched commit
- There is an explanation of why the vulnerable commit is vulnerable

### Improving analysis tool information

While each CVE benchmark contain information about the weaknesses that
could be flagged by an analysis tool. It may not be enough for the
analysis tool to decide the rules that apply to a CVE, nor may it be
enough for the analysis tool to know if one of its alerts is a true or
false positive. Maintaining tool-specific CVE information is therefore
encouraged to get the best comparisons.

** IT IS UP TO EACH TOOL HOW IT REPRESENTS THIS DATA **

There are no tool-specific information for individual CVEs in this
repository, maintenance of such data sets is done else where.  Plugin
improvements that allows the usage of such information is welcome in
this repository.

** IS THIS A REASONABLE SEPARATION? **

## Contributing code

This project contains two source code directories: [src](src) and
[contrib](contrib). [src](src) is for the core tooling, and is
primarily maintained by a core team of developers. [contrib](contrib)
contains utility scripts, such as the [analysis tool
plugins](contrib/tools). The content of [contrib](contrib) could just
as well live in several other repositories.

### Analysis tools plugins

Analysis tools plugins are small scripts that runs an actual analysis
tool when invoked by `bin/cli run ...`.

To add out-of-the-box support for a new analysis tool plugin, add a
new directory to the [contrib/tools](contrib/tools), and read the
requirements for the plugins in the [docs](contrib/tools/README.md)

#### List of anslysis tool plugins

Some versions of the following analysis tools are supported:

 - [CodeQL](https://securitylab.github.com/tools/codeql) 
 - [Fortify](https://www.microfocus.com/en-us/solutions/application-security) 
 - [eslint](https://eslint.org/)
 - [nodejsscan](https://github.com/ajinabraham/nodejsscan)
 - [pmd](https://pmd.github.io/)
 
## Example experiments

This section describes various experiments that can be performed with
the tooling in this repository. The exact implementation are left as
an excercise.

### Comparing true positive rates

When comparing competing analysis tools, a simple measure is to
compare the number of CVEs each analysis can detect.

- input: 
  - tool-ids: `tool-A@vX`, `tool-B@vY`, `tool-C@vZ`
  - CVEs: any fixed group
- output: 
  - the number of CVEs that each analysis tool produces a true positive alert for

### Comparing false positive rates

When comparing competing analysis tools, a simple measure is to
compare the number of CVEs each analysis can detect the fix for.

- input:
  - tool-ids: `tool-A@vX`, `tool-B@vY`, `tool-C@vZ`
  - CVEs: any fixed group
- output:
  - the number of CVEs that each analysis tool does not produce a
    false positive alert for once the vulnerability has been patched

### Comparing CWE coverage

Like above, but the CVEs are selected based on their CWEs.

### Monitoring incremental analysis tools improvements

As an analysis tool improves, it is expected that it wil be able to
report additional true positives, and fewer false positives.

- input: 
  - tool-ids: `tool@v1`, `tool@v2`, `tool@v3`, `tool@v4`
  - CVEs: any fixed group
- output: 
  - presumably increasing precision and recall from for the sequence `v1`, `v2`,`v3`,`v4`
  
### Comparing the predictive power and responsiveness of analysis tools

An analysis tool is most useful if it can detect vulnerability classes
before they start trending. If a vulnerability class is popular one
year, chances are that some analysis tools will have support for them
the year after that. This poses two interesting questions: which
analysis tools already had support for the vulnerabilities, and which
where responsive enough to add support soon after the discovery?

This can be answered by two experiments:

- input:
  - tool-ids: `tool-A@v2019`, `tool-B@v2019`, `tool-C@2019`
  - CVEs: CVE-2020- ...
- output:
  - the analysis tools that had support for the vulnerabilities already

- input
  - tool-ids: `tool-A@v2020`, `tool-B@v2020`, `tool-C@2020`
  - CVEs: CVE-2019- ...
- output:
  - the analysis tools that had support for the vulnerabilities the following year

## Implementation status

- additional, and more polished, data from the javascript repository is required!
- code documentation is generally absent
- the README plugins have not been written 
- tests are absent, the example `bin/cli` session at the top of this document should be used as the reference for what should work
- an asynchronous (through Actions) plugin should be supported
- a more sales-friendly report generator is needed
- at the time of writing, this project uses code with the following licenses
  - MIT: 34
  - Python-2.0: 1
  - ISC: 1
  - BSD-3-Clause: 1
  - Apache-2.0: 1
  - BSD-2-Clause: 1
